# Detailed Story of [ljyda214](https://github.com/samchon)
## Table of Contents
- [Detailed Story of ljyda214](#detailed-story-of-ljyda214)
  - [Table of Contents](#table-of-contents)
  - [1. Introduction](#1-introduction)
    - [1.1.관심](#11관심)
    - [1.2.개발 경험](#12개발-경험)
    - [1.3.개발 목표](#13개발-목표)
    - [1.4.기술적 강점](#14기술적-강점)
  - [2. Commercial Projects](#2-commercial-projects)
    - [2.1. CDC 를 활용한 데이터 조회 DB 변경](#21-cdc-를-활용한-데이터-조회-db-변경)
      - [Problem](#problem)
      - [Approach](#approach)
      - [Result](#result)
      - [사용 기술](#사용-기술)
    - [2.2. 쿠버네티스 기반의 데이터 파이프라인 중계 서버 구축](#22-쿠버네티스-기반의-데이터-파이프라인-중계-서버-구축)
      - [Problem](#problem-1)
      - [Approach](#approach-1)
      - [Result](#result-1)
      - [사용 기술](#사용-기술-1)
    - [2.3. 온프레미스 인프라의 데이터 수집을 위한 데이터 전처리 및 업로드 애플리케이션 개발](#23-온프레미스-인프라의-데이터-수집을-위한-데이터-전처리-및-업로드-애플리케이션-개발)
      - [Problem](#problem-2)
      - [Approach](#approach-2)
      - [Result](#result-2)
      - [사용 기술](#사용-기술-2)
    - [2.4. WebSocket 기반 실시간 차량 데이터 스트리밍 서비스 개발](#24-websocket-기반-실시간-차량-데이터-스트리밍-서비스-개발)
      - [Problem](#problem-3)
      - [Approach](#approach-3)
      - [Result](#result-3)
      - [사용 기술](#사용-기술-3)


## 1. Introduction
### 1.1.관심
- 다양한 형태와 사이즈의 데이터들을 안정적으로 처리하는 시스템에 대한 지속적인 관심과 경험
- 서비스 콘텐츠들을 사용자들에게 빠르고 안정적으로 전달하는 기술력에 관심
### 1.2.개발 경험
- 다양한 형태의 데이터를 실시간으로 처리하고 안정적으로 전달하는 시스템 설계를 경험
- 데이터 파이프라인을 수행하는 작업 서버들을 구축하고 관리하는 시스템을 설계, 개발, 유지보수
- 로컬의 데이터들을 파이프라인 처리한 후 업로드하는 과정에 발생 가능한 데이터 유실, 중복, 지연 등의 장애 상황을 가정한 시나리오 기반 개발을 수행
- 장애나 여러 이슈로 인해 업로드 실패 시 폴백 전략들을 통한 장애 복구 방안을 고민
- 메시지 기반 비동기 연동을 데이터 파이프라인 처리에 적용
### 1.3.개발 목표
- 많은 트래픽 속에서 빠른 콘텐츠 전송, 트래픽 증가에 대응 가능한 구조적 유연성, 장애 발생 시 복구 가능한 설계 방식, 운영 중인 시스템의 신뢰도 향상을 목표로 개발을 수행함
- 팀 내부적으로 서비스 안정성과 코드 품질 및 유지보수 개선에 기여하고자 하며, 서비스 전반의 신뢰도를 높이는 방향으로 협업에 참여하는 것을 좋아합니다.
### 1.4.기술적 강점
- 확장성과 유지보수성을 고려한 시스템 아키텍처 설계 및 구현 능력
- 항상 '시스템은 변화에 유연하게 대응'할 수 있어야 하며, '장애가 발생해도 전체 서비스에 미치는 영향을 최소화'해야 한다는 것에 유의하며 아키텍쳐를 설계합니다.
-  서비스 간 동기/비동기 통신을 구현하는 다양한 기술적 역량을 보유
- 성능과 안정성을 균형 있게 고려하고 있으며, 서비스 간 연동
- 과정에서 발생할 수 있는 장애의 영향을 최소화하는 설계를 우선적으로 고려
- 외부 연동과 트랜잭션 처리에 있어 폴백, 보상 트랜잭션, 데이터 후처리 등 다양한 패턴을 상황에 맞게 적용할 수 있는 실무적 경험을 보유
- 클라우드 네이티브 환경에서의 시스템 설계 및 운영 능력
- 데이터 업로드에서부터 데이터 파이프라인 처리까지 Data journey 를 개발, 운영한 경험


## 2. Commercial Projects

### 2.1. CDC 를 활용한 데이터 조회 DB 변경
프로젝트 기간: 2025-08 ~ 진행 중
#### Problem
- 비정형성 구조의 데이터를 RDB 의 하나의 테이블에 저장하였고, 이로 인해 해당 데이터에 대한 비즈니스 요구사항에 대한 기능의 구현 복잡도가 상승
- 데이터량 증가에 따라 복잡한 Join/Filter 구조가 발생하여 쿼리 성능이 저하되었고, 인덱스 튜닝만으로는 해결할 수 없는 한계에 도달
#### Approach
- RDB 대신 비정형 데이터의 조회 목적에 부합하는 Document DB(MongoDB)로의 데이터 이전을 결정
  - 비정형 데이터에 대한 조회는 MongoDB 를 통해 수행하도록 쓰기와 읽기 로직을 분리
- RDB 에 저장되는 데이터를 CDC 기술인 Debezium 을 Kafka 의 source connector 로 활용하여 MongoDB 에 실시간으로 반영하는 구조 설계
  - MongoDB를 통한 비정형 데이터 저장 방식 설계
  - Debezium을 통해 RDB의 실시간 변경을 감지하고, 이를 Kafka 에 메시지로 발행하는 시스템 구축
  - Kafka 에서 메시지를 수신하여 MongoDB에 데이터를 저장하는 Sync connector 개발
#### Result
- 비정형 데이터에 대한 데이터 가시성 및 확장성 확보
- 데이터의 조회 및 저장 속도의 개선
  - 1억건의 데이터 기준으로 데이터 조회 시, RDB 에서는 30초 이상 소요되어 Timeout 이 발생했으나, MongoDB 에서는 900ms 이내로 데이터 조회 수행
  - 30,000 건 데이터 기준으로 MongoDB 에 데이터를 적재하는데 17ms 소요
- 트래픽 분산 및 쿼리 수 감소로 RDB의 부하가 경감
- 쓰기(RDB)와 읽기(MongoDB) 목적을 분리함으로써 유연한 아키텍처 구성
#### 사용 기술
- Spring boot, Kafka, Debezium, MongoDB

### 2.2. 쿠버네티스 기반의 데이터 파이프라인 중계 서버 구축
프로젝트 기간: 2025-06 ~ 2025-08
#### Problem
- 데이터 파이프라인을 수행하는 데이터 프로세싱 서버들의 생성/삭제가 실제 사용자에게 제공되는 정보와 동기화되지 않는 서비스 구조
- 데이터 프로세싱 서버들의 작업 진행에 대한 추적이 되지 않아, 사용자가 작업의 성공/실패 여부의 확인을 인지할 수 없는 서비스 구조
- 도커 기반에서 쿠버네티스 기반으로 인프라 환경을 이전하면서 데이터 프로세싱 서버들을 관리(생성/작업요청/삭제)하는 기능이 정상 동작하지 않는 문제 발생
#### Approach
- 데이터 프로세싱 서버의 생성/삭제 요청에 대한 Fallback 전략 도입
  - 요청 실패에 대한 요청 재시도 구현
    - 재시도 요청 간 대기시간에 대해 지수로 증가하는 Backoff 전략 도입
- 문제가 지속되는 서버에 대한 요청을 방지하고자 Circuit breaker 패턴 도입
  - 데이터 프로세싱 서버의 작업 진행을 추적할 수 있는 구조로 아키텍처를 개편
  - 사이드카 패턴을 구현하여 데이터 프로세싱 서버의 readiness 상태 체크 진행
  - 쿠버네티스의 Informer 를 활용하여 로컬 캐시와 이벤트 핸들러를 통해 실시간으로 데이터 프로세싱 서버의 상태를 업데이트
  - 데이터 프로세싱 서버마다 작업 진행 단계 별로 결과를 전달하도록 개편하여, 데이터 파이프라인 처리 상황을 니어 리얼타임으로 갱신
  - 문제가 발생한 데이터 프로세싱 서버에 대한 정보를 SSE 를 통해 사용자에게 알람 전달
- 도커 컨테이너 기반에서 쿠버네티스 기반으로 시스템 재설계
  - 인프라 환경과 강결합된 기능들을 추상화하여 외부 의존성 제거
#### Result
- 데이터 프로세싱 서버의 상태 정보를 통한 데이터 파이프라인의 운영 가시성 확보
- 데이터 파이프라인 수행에 대한 진행 상황을 니어 리얼타임으로 사용자에게 제공
- 중계 서버를 인프라 환경에 영향받지 않는 형태로 개선
#### 사용 기술
- Spring Boot, SSE, MySQL, RabbitMQ, Kubernetes

### 2.3. 온프레미스 인프라의 데이터 수집을 위한 데이터 전처리 및 업로드 애플리케이션 개발
프로젝트 기간: 2025-01 ~ 2025-04
#### Problem
- 사용자가 업로드한 데이터들의 이전 기록을 확인할 수 없는 사항에 대한 불만 사항 전달
- 애플리케이션에서 이상 종료 발생 시, 수행 중이던 작업 기록이 소실
- 애플리케이션의 작업 상태에 따라 내부 동작의 로직이 복잡도가 증가
#### Approach
- 과거 작업 기록을 추적할 수 있는 기능 개발
  - Embedded H2 Database 를 도입하여 데이터 관리 유효성 확보
- 진행 중인 작업 기록을 저장하여, 재기동 시 수행 중이던 작업을 재개하도록 기능 변경
- 데이터 파이프라인 수행 상태를 SSE 를 통해 실시간으로 사용자에게 전달
- 애플리케이션의 상태에 의존적인 형태로 동작하지 않도록 내부 설계 변경
  - 애플리케이션의 상태에 따라 다른 동작을 수행하도록 기능의 추상화 진행
#### Result
- 사용자가 업로드한 데이터들의 이전 기록을 확인할 수 있는 기능 제공
- 애플리케이션에서 이상 종료에 상관없이 요청한 작업이 정상 진행되도록
- 애플리케이션의 작업 상태에 따라 내부 동작의 로직이 복잡도가 증가
#### 사용 기술
- Spring Boot, SSE, ActiveMQ, H2 Database, Electron

### 2.4. WebSocket 기반 실시간 차량 데이터 스트리밍 서비스 개발
프로젝트 기간: 2024-09 ~ 2025-01
#### Problem
- 이미지, 차량 신호, GPS 등 다양한 시계열 데이터들에 대한 데이터 동기화를 클라이언트에서 처리하는 구조로 인해, 동기화를 맞춰야 하는 데이터의 개수가 늘어나거나 데이터의 사이즈가 커질 경우 데이터 간 동기화 정확도가 저하되는 현상이 발생
  - 정확하지 않은 데이터 동기화에 따른 사용자 경험 감소
  - 데이터 동기화에 따른 클라이언트의 부하 증가로 인한 성능 이슈 발생
#### Approach
- 이미지, 차량 신호, GPS 등의 다양한 데이터들을 영상의 특정 프레임 단위로 스트리밍하는 시스템 설계
  - 각 도메인의 데이터(Signal, GPS 등)를 서버에서 시간 기준 정렬 및 통합 처리하고, 클라이언트는 전달받은 데이터의 렌더링만 담당하도록 서비스 구조 개편
- 데이터 전송 방식을 HTTP API 기반의 Json 포맷에서 WebSocket 기반의 Protobuf 포맷으로 전환
- 여러 데이터 파일의 IO 및 메시지 전송 과정을 WebFlux를 활용하여 비동기 논블로킹 방식으로 구현
#### Result
- 클라이언트 처리 부하 감소, 데이터 동기화의 정확도 향상
- 스트리밍 속도 약 30% 개선, 브라우저 부하 감소
#### 사용 기술
- Spring WebFlux, WebSocket, FFmpeg, Protobuf, k6
